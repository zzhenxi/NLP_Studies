{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFpYA13POXd2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCyAL3dyOXd6"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_aD0uLjOXd6"
      },
      "source": [
        "# Pytorch Graph\n",
        "`torch.nn` 모듈은 텐서 그래프를 생성하는 다양한 함수를 제공한다. \n",
        "\n",
        "[OFFICAL DOCUMENT](https://pytorch.org/docs/stable/nn.html)\n",
        "\n",
        "# Table of Contents\n",
        "1. [Container](#Container)\n",
        "2. [Layers](#Layers)\n",
        "3. [Loss](#Loss)\n",
        "4. [추가](#To-Learn-More..)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qD83YOocOXd8"
      },
      "source": [
        "## Container\n",
        "- [OFFICIAL DOC](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#module)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swW0tvvLOXd9"
      },
      "source": [
        "### `Module` class \n",
        "- Neural Network를 생성할 때 반드시 `Module` 클래스를 부모 클래스로 상속받아야 함\n",
        "- `Module` 부모 클래스의 변수 및 메소드 사용 가능 (ex. `eval()`, `train()`, `parameters()`, `state_dict()`, `to()`)\n",
        "- `forward()` 메소드는 모든 자식클래스에서 반드시 **오버라이딩** 해야함\n",
        "- [출처](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxmY0tS-OXd9"
      },
      "source": [
        "<img src=\"https://github.com/ChristinaROK/PreOnboarding_AI_assets/blob/36a670a7b6233d5218a495150beb337a899ecb70/week2/week2_2_model.jpeg?raw=true\" alt=\"model\" width=600>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZKTOfJqOXd-"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, input_shape):\n",
        "        super(Model, self).__init__()\n",
        "        self.layer1 = nn.Linear(input_shape, 32)\n",
        "        self.layer2 = nn.Linear(32, 64)\n",
        "        self.layer_out = nn.Linear(64,1)\n",
        "        \n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.layer1(x))\n",
        "        x = self.relu(self.layer2(x))\n",
        "        x = self.layer_out(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lgtRKMcOXd_"
      },
      "outputs": [],
      "source": [
        "model = Model(30)\n",
        "\n",
        "for param in model.parameters():\n",
        "    print(param.shape)\n",
        "\n",
        "for name, state in model.state_dict().items():\n",
        "    print(f\"{name} -> size : {state.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aucu7uHOXeA"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caZPdvpqOXeB"
      },
      "source": [
        "### `Sequntial` class\n",
        "- 여러 layer를 연결한 container\n",
        "- 이전 layer의 output이 다음 layer의 input으로 입력됨 (순차적)\n",
        "- [출처](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGphSFCfOXeC"
      },
      "outputs": [],
      "source": [
        "model = nn.Sequential(\n",
        "          nn.Linear(30, 32),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(32,64),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(64,1)\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYRuf5fwOXeC"
      },
      "outputs": [],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKHmnkicOXeD"
      },
      "source": [
        "## Layers\n",
        "- Linear()\n",
        "    - `input @ weight.T + bias`\n",
        "- LSTM()\n",
        "    - [OFFICAL DOCS](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html#torch.nn.LSTM) \n",
        "    - nn.LSTM(`input_size`, `hidden_size`)\n",
        "        - nn.LSTM()(`input`, (`h_0`, `c_0`))\n",
        "        - `input` shape: (문장 길이, 배치 사이즈, 단어 엠베딩 사이즈 == input_size)\n",
        "        - `hidden_size` shape: (lstm 개수 * 레이어 수 , 배치 사이즈, 히든 사이즈 == hidden size)\n",
        "    - <img src=\"https://github.com/ChristinaROK/PreOnboarding_AI_assets/blob/36a670a7b6233d5218a495150beb337a899ecb70/week2/week2_2_lstm.png?raw=true\" width=500>\n",
        "    - [출처](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yK0WSgOGOXeD"
      },
      "outputs": [],
      "source": [
        "model = nn.Linear(20,30) \n",
        "print(f\"W shape: {model.weight.shape}\")\n",
        "print(f\"bias shape: {model.bias.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sH7oL6tOXeD"
      },
      "outputs": [],
      "source": [
        "ex = \"I love coding . Just kidding .\"\n",
        "inputs = ex.split()\n",
        "print(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9mEp504OXeE"
      },
      "outputs": [],
      "source": [
        "input_embedding = [torch.randn(1, 5) for _ in range(len(inputs))]\n",
        "\n",
        "lstm = nn.LSTM(5,5) # (input dim, output dim)\n",
        "hidden = (\n",
        "    torch.randn(1,1,5), # (모든 레이어의 lstm 개수, batch size, hidden_size)\n",
        "    torch.randn(1,1,5),\n",
        ")\n",
        "\n",
        "# 한 단어씩 입력\n",
        "for idx, i in enumerate(input_embedding):\n",
        "    out, hidden = lstm(i.view(1,1,-1), hidden)\n",
        "    print(f\"{idx+1} word : output shape ({out.shape}) / hidden state shape ({hidden[0].shape})\")\n",
        "\n",
        "assert out.detach().equal(hidden[0].detach())\n",
        "\n",
        "print(\"----------------------------------\")\n",
        "\n",
        "# sequence를 입력\n",
        "input_embedding = torch.cat(input_embedding).view(len(inputs), 1, -1)\n",
        "print(f\"input sequence shape : {input_embedding.shape}\")\n",
        "hidden = (\n",
        "    torch.randn(1,1,5), # (모든 레이어의 lstm 개수, batch size, hidden_size)\n",
        "    torch.randn(1,1,5),\n",
        ")\n",
        "out, hidden = lstm(input_embedding, hidden)\n",
        "print(f\"output shape : {out.shape}\")\n",
        "print(f\"hidden shape : {hidden[0].shape}\")\n",
        "\n",
        "assert out[-1, : , :].detach().equal(hidden[0][-1, :,:].detach())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7W8jXimOXeE"
      },
      "source": [
        "## Activation\n",
        "- nonlinear activations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9dWNYeMOXeF"
      },
      "outputs": [],
      "source": [
        "nn.LeakyReLU()\n",
        "nn.ReLU()\n",
        "nn.Sigmoid()\n",
        "nn.GELU()\n",
        "nn.Tanh()\n",
        "nn.Softmax()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdLlMN8gOXeF"
      },
      "source": [
        "## Loss\n",
        "- loss = loss_class()\n",
        "    - loss(`y_hat`, `y`)\n",
        "    - `loss().backward()`\n",
        "- Mean Square Error Loss \n",
        "    - <img src=\"https://github.com/ChristinaROK/PreOnboarding_AI_assets/blob/36a670a7b6233d5218a495150beb337a899ecb70/week2/week2_2_mse.png?raw=true\" width=200>\n",
        "- Cross Entropy Loss \n",
        "    - <img src=\"https://github.com/ChristinaROK/PreOnboarding_AI_assets/blob/36a670a7b6233d5218a495150beb337a899ecb70/week2/week2_2_ce.png?raw=true\" width=200>\n",
        "- Binary Cross Entropy Loss \n",
        "    - <img src=\"https://github.com/ChristinaROK/PreOnboarding_AI_assets/blob/36a670a7b6233d5218a495150beb337a899ecb70/week2/week2_2_bce.png?raw=true\" width=500>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-E-xUS4OXeF"
      },
      "outputs": [],
      "source": [
        "# l2 distance loss\n",
        "nn.MSELoss()\n",
        "\n",
        "# cross entropy\n",
        "## multi class\n",
        "nn.CrossEntropyLoss() # softmax O\n",
        "\n",
        "## binary class\n",
        "nn.BCELoss()\n",
        "nn.BCEWithLogitsLoss() # sigmoid O + BCELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyAB7IOHOXeF"
      },
      "outputs": [],
      "source": [
        "batch_size = 3\n",
        "C = 5\n",
        "logits = torch.randn(batch_size, C, requires_grad=True)\n",
        "print(f\"Logits : {logits}\")\n",
        "\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "target = torch.empty(batch_size, dtype = torch.long).random_(C)\n",
        "print(f\"Target: {target}\")\n",
        "\n",
        "loss = loss(logits, target)\n",
        "print(f\"Loss : {loss}\")\n",
        "\n",
        "loss.backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFXZ_5iyOXeF"
      },
      "source": [
        "## To Learn More..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVPCKAB4OXeG"
      },
      "outputs": [],
      "source": [
        "# dropout\n",
        "nn.Dropout()\n",
        "# normalization\n",
        "nn.BatchNorm1d()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ob1cZqEuOXeG"
      },
      "outputs": [],
      "source": [
        "# gradient clipping\n",
        "nn.utils.clip_grad()\n",
        "# weight normalizing\n",
        "nn.utils.weight_norm()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5XCnZIaOXeG"
      },
      "source": [
        "### Parallel\n",
        "- 여러 gpu, 또는 여러 머신에서 입력 데이터를 분산 처리를 가능하게 함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qw5inpiAOXeG"
      },
      "outputs": [],
      "source": [
        "nn.DataParallel()\n",
        "nn.parallel.DistributedDataParallel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJidrZTfOXeG"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "cc8ea02fb777342a894a6da130bb5db32fa16020fe93af80059107733690b37d"
    },
    "kernelspec": {
      "display_name": "torch",
      "language": "python",
      "name": "torch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "colab": {
      "name": "Week2_2_torch_tutorial_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}